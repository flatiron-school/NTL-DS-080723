{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pandas-Data-Cleaning\" data-toc-modified-id=\"Pandas-Data-Cleaning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pandas Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#To-The-Center!\" data-toc-modified-id=\"To-The-Center!-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>To The Center!</a></span></li><li><span><a href=\"#Using-Questions-to-Drive-Both-Exploration-and-Cleaning\" data-toc-modified-id=\"Using-Questions-to-Drive-Both-Exploration-and-Cleaning-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Using Questions to Drive Both Exploration and Cleaning</a></span></li><li><span><a href=\"#Question-1:-How-old-are-the-animals-in-our-dataset?\" data-toc-modified-id=\"Question-1:-How-old-are-the-animals-in-our-dataset?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Question 1: How old are the animals in our dataset?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Handling-Missing-Data\" data-toc-modified-id=\"Handling-Missing-Data-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Handling Missing Data</a></span></li><li><span><a href=\"#Map,-Apply-and-Applymap\" data-toc-modified-id=\"Map,-Apply-and-Applymap-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Map, Apply and Applymap</a></span></li></ul></li><li><span><a href=\"#Question-2:-Are-Most-of-The-Animals-Already-Fixed?\" data-toc-modified-id=\"Question-2:-Are-Most-of-The-Animals-Already-Fixed?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Question 2: Are Most of The Animals Already Fixed?</a></span></li><li><span><a href=\"#A-Quick-Aside---for-Lambda-Functions!\" data-toc-modified-id=\"A-Quick-Aside---for-Lambda-Functions!-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>A Quick Aside - for Lambda Functions!</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-More-Strategy:-Build-a-Missing-Indicator\" data-toc-modified-id=\"One-More-Strategy:-Build-a-Missing-Indicator-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>One More Strategy: Build a Missing Indicator</a></span></li></ul></li><li><span><a href=\"#Comparing-Before-and-After\" data-toc-modified-id=\"Comparing-Before-and-After-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Comparing Before and After</a></span></li></ul></li><li><span><a href=\"#Level-Up:-.applymap()\" data-toc-modified-id=\"Level-Up:-.applymap()-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Level Up: <code>.applymap()</code></a></span></li><li><span><a href=\"#Level-Up:-Faster-NumPy-Methods\" data-toc-modified-id=\"Level-Up:-Faster-NumPy-Methods-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Level Up: Faster NumPy Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#NumPy's-where()-Method\" data-toc-modified-id=\"NumPy's-where()-Method-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>NumPy's <code>where()</code> Method</a></span></li><li><span><a href=\"#NumPy's-select()-Method\" data-toc-modified-id=\"NumPy's-select()-Method-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>NumPy's <code>select()</code> Method</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![panda](http://res.freestockphotos.biz/thumbs/3/3173-illustration-of-a-giant-panda-eating-bamboo-th.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pandas Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Handle missing data, and recognize when different strategies for handling missing data would be appropriate\n",
    "- Use DataFrame methods (and sometimes lambda functions) to transform data\n",
    "- Use string methods to transform object-type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:36.236905Z",
     "start_time": "2023-04-10T16:01:35.033406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## To The Center!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That's right - we're still working with Austin Animal Center data! But now, let's check out the Outcomes data, instead of the Intakes data we were working with before.\n",
    "\n",
    "Data source: https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:03:16.180905Z",
     "start_time": "2023-04-10T16:02:59.922436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in the animal center outcomes data as df\n",
    "# Can use parse_dates and pass a column name to read it as a datetime\n",
    "df = pd.read_csv('data/Austin_Animal_Center_Outcomes_022822.csv',\n",
    "                 parse_dates=['DateTime', 'Date of Birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:03:16.273906Z",
     "start_time": "2023-04-10T16:03:16.244906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:03:16.397906Z",
     "start_time": "2023-04-10T16:03:16.322908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Info on the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:06:24.425406Z",
     "start_time": "2023-04-10T16:06:24.119906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Questions to Drive Both Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best way to think about how to both explore and clean your data set is to think about what is interesting in your data, what questions you have, what you want to know and how to actually get there. We're going to ask a few questions of our dataset, and use that to drive our 'cleaning' process (and talk a little bit about how and when to clean data in the process!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Question 1: How old are the animals in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try to answer this with the `Age upon Outcome` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:07:32.081906Z",
     "start_time": "2023-04-10T16:07:32.051408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Oh no! These aren't numbers! And the data is pretty dirty! Let's see how we can break this column apart, into the Age Number and the Age Unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:09:55.448905Z",
     "start_time": "2023-04-10T16:09:54.661407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split out the age number and age unit - using string methods!\n",
    "df['Age Number'] = df['Age upon Outcome'].str.split().str[0]\n",
    "df['Age Unit'] = df['Age upon Outcome'].str.split().str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:10:21.160414Z",
     "start_time": "2023-04-10T16:10:21.138406Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:10:44.379406Z",
     "start_time": "2023-04-10T16:10:44.283906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check the data types really quick...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:11:46.487906Z",
     "start_time": "2023-04-10T16:11:46.447406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Need to make our Age Number actual numbers! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Alas! Nulls! Let's check out these null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:16:55.495908Z",
     "start_time": "2023-04-10T16:16:55.473406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check how many nulls we have in our original Age Upon Outcome column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:17:02.594906Z",
     "start_time": "2023-04-10T16:17:02.565407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A lot of the times we'll have missing information in our data set. This can sometimes be troublesome in what we're trying to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are a few strategies we can choose from and they each have their pros/cons:\n",
    "\n",
    "- **Fill with a Relevant Value**\n",
    "    - If we know what the nulls 'should' be, easy to fill them with that value\n",
    "    - For numbers, perhaps the null indicates a 0\n",
    "    - Or, for string columns, might be easier to handle if we fill with \"Missing\" or \"Unknown\"\n",
    "- **Fill with a Reasonable Value**\n",
    "    - For numeric data, it might be acceptable to fill with a measure of central tendency (mean or median)\n",
    "    - For categorical/string data, might be acceptable to fill with the most common (mode)\n",
    "    - But beware! Filling in missing values can lead to you drawing incorrect conclusions. If most of the data from a column are missing, it's going to appear that the value you filled it in with is more common that it actually was!\n",
    "- **Specify Missing Data**\n",
    "    - If you plan to fill in missing values, it might make sense to specify that the data was originally missing by creating a new indicator column\n",
    "    - This can be helpful when you suspect that the fact the data was missing could be important for an analysis.\n",
    "- **Drop Missing Data**\n",
    "    - While you should try to keep as much relevant data as possible, sometimes the other methods don't make as much sense and it's better to remove or **drop** the missing data\n",
    "    - We typically drop missing data if very little data would be lost and/or trying to fill in the values wouldn't make sense for our use case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So: what should we do about the missing Age upon Outcome data?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "    <summary>Possible Answer</summary>\n",
    "\n",
    "- It's probably okay to drop the missing data in this case - not very many rows with nulls in that column\n",
    "- Should look at the percentage of the total (aka what percentage of rows would be dropped) to justify this decision\n",
    "    \n",
    "    \n",
    "Note! There is a Date of Birth column that does not have any nulls! But we're specifically trying to use Age Upon Outcome here because it helps us practice some other tactics for cleaning data.\n",
    "    \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:18:02.533406Z",
     "start_time": "2023-04-10T16:18:02.500906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# No matter what - better to make this change on a COPY of the dataframe\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:18:37.904406Z",
     "start_time": "2023-04-10T16:18:37.860909Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code here to handle nulls\n",
    "df_clean = df_clean.dropna(subset=['Age upon Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:18:38.663906Z",
     "start_time": "2023-04-10T16:18:38.600907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:18:49.699907Z",
     "start_time": "2023-04-10T16:18:49.651407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cool - now we can make our Age Number column an integer\n",
    "df_clean['Age Number'] = df_clean['Age Number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:18:50.955408Z",
     "start_time": "2023-04-10T16:18:50.896906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's do something about those Age Values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Map, Apply and Applymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Resource](https://www.geeksforgeeks.org/difference-between-map-applymap-and-apply-methods-in-pandas/)\n",
    "\n",
    "The `.map()` method applies a transformation to every entry in the Series. This transformation  \"maps\" each value from the Series to a new value. A transformation can be defined by a function, Series, or dictionary.\n",
    "\n",
    "The `.apply()` method is similar to the `.map()` method for Series, but can only take in functions. \n",
    "\n",
    "The `.applymap()` method only works on DataFrames, and applies the same transformation to every element (cell) of that DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:20:17.429905Z",
     "start_time": "2023-04-10T16:20:17.389407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean['Age Unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:21:32.883906Z",
     "start_time": "2023-04-10T16:21:32.867906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Providing this dictionary to capture age values in # days (not perfect)\n",
    "age_vals = {\n",
    "    'years': 365,\n",
    "    'year': 365,\n",
    "    'months': 30,\n",
    "    'month': 30,\n",
    "    'weeks': 7,\n",
    "    'week': 7,\n",
    "    'days': 1,\n",
    "    'day': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:21:58.877407Z",
     "start_time": "2023-04-10T16:21:58.826905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now, how can we transform the Age Value column to capture these values?\n",
    "df_clean['Age Unit'] = df_clean['Age Unit'].map(age_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:22:05.914406Z",
     "start_time": "2023-04-10T16:22:05.885907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:22:19.445906Z",
     "start_time": "2023-04-10T16:22:19.380908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:23:13.277406Z",
     "start_time": "2023-04-10T16:23:13.256406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now, let's make a new Age in Days column!\n",
    "df_clean['Age in Days'] = df_clean['Age Number'] * df_clean['Age Unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:23:18.361411Z",
     "start_time": "2023-04-10T16:23:18.339907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:24:12.595906Z",
     "start_time": "2023-04-10T16:24:12.350407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now we can visualize!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:25:14.223907Z",
     "start_time": "2023-04-10T16:25:11.859906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:26:09.806906Z",
     "start_time": "2023-04-10T16:26:09.787406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:30.282906Z",
     "start_time": "2023-04-10T16:27:30.261907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Of course, we could also try...\n",
    "# Use .dt.normalize on the DateTime column to access the date!\n",
    "\n",
    "\n",
    "df_clean['Calculated Age in Days'] = df_clean['DateTime'].dt.normalize() - df_clean['Date of Birth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:34.793405Z",
     "start_time": "2023-04-10T16:27:34.772407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check it\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:54.555907Z",
     "start_time": "2023-04-10T16:27:54.484906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Question 2: Are Most of The Animals Already Fixed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's use `.map()` to turn the Sex upon Outcome column into a category with three values: Fixed, Intact, or Unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:29:36.700907Z",
     "start_time": "2023-04-10T16:29:36.683407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out what's currently in that column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:29:50.650906Z",
     "start_time": "2023-04-10T16:29:50.636407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean['Sex upon Outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:30:24.595905Z",
     "start_time": "2023-04-10T16:30:24.586906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can write a function for this\n",
    "def fixed_mapper(status):\n",
    "    '''\n",
    "    Takes in the current status of animals and outputs whether they have been fixed\n",
    "    '''\n",
    "    if status in ['Neutered Male', 'Spayed Female']:\n",
    "        return 'Fixed'\n",
    "    elif status in ['Intact Male', 'Intact Female']:\n",
    "        return 'Intact'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:31:22.937906Z",
     "start_time": "2023-04-10T16:31:22.904406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now let's use it!\n",
    "df_clean['Grouped Sex upon Outcome'] =df_clean['Sex upon Outcome'].map(fixed_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:32:18.024906Z",
     "start_time": "2023-04-10T16:32:17.969408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean[['Sex upon Outcome','Grouped Sex upon Outcome']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:33:00.278906Z",
     "start_time": "2023-04-10T16:33:00.215406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We had a null in that column before, did that change?\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:34:33.200405Z",
     "start_time": "2023-04-10T16:34:33.057407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Visualize it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Quick Aside - for Lambda Functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Simple functions can be defined just when you need them, when you would call the function. These are called **lambda functions**. These functions are **anonymous** and disappear immediately after use.\n",
    "\n",
    "These can often be great as map transformation functions, but they can only do so much.\n",
    "\n",
    "Let's use them to fill some nulls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:35:28.116905Z",
     "start_time": "2023-04-10T16:35:28.061405Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check which columns still have null values\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at Outcome Subtype - a lot of nulls, why do we think that is? What would be an appropriate strategy here?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "    <summary>Possible Answer</summary>\n",
    "\n",
    "- Might be that the Type doesn't have Subtypes, or that there hasn't been an outcome yet\n",
    "- Would be appropriate to fill with N/A\n",
    "    \n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:36:03.472406Z",
     "start_time": "2023-04-10T16:36:03.440909Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's try it!\n",
    "# Note: need to use x is np.nan as our if condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:36:58.853907Z",
     "start_time": "2023-04-10T16:36:58.825906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# BUT! Pandas has a function for this\n",
    "df_clean['Outcome Subtype'] = df_clean['Outcome Subtype'].fillna(\"N/A\")\n",
    "df_clean['Outcome Subtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:37:53.382907Z",
     "start_time": "2023-04-10T16:37:53.357906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean['Outcome Subtype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:37:13.501408Z",
     "start_time": "2023-04-10T16:37:13.480408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can use one of these methods to fill the nulls for Outcome Type too\n",
    "# Explore the column here\n",
    "df_clean['Outcome Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:38:08.867407Z",
     "start_time": "2023-04-10T16:38:08.855907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill nulls here\n",
    "df_clean['Outcome Type'] = df_clean['Outcome Type'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:38:09.456406Z",
     "start_time": "2023-04-10T16:38:09.397908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### One More Strategy: Build a Missing Indicator\n",
    "\n",
    "While this doesn't directly answer a question we have, let's go ahead and build a new column to indicate where Name is null (just to demo).\n",
    "\n",
    "This can be quite useful when modeling, if the data being missing actually means something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:39:25.204907Z",
     "start_time": "2023-04-10T16:39:25.188406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quick pandas method for this\n",
    "df_clean['Name Missing'] = df_clean['Name'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:39:34.442906Z",
     "start_time": "2023-04-10T16:39:34.421908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Might be more interesting to build an indicator of where \"Mix\" is in the Breed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:41:00.266407Z",
     "start_time": "2023-04-10T16:41:00.192408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's do it\n",
    "df_clean['Mix Indicator'] = df_clean['Breed'].str.contains(' Mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:41:04.311907Z",
     "start_time": "2023-04-10T16:41:04.287906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Comparing Before and After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now see all the work we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:41:46.055408Z",
     "start_time": "2023-04-10T16:41:45.977907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Original data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:41:48.068407Z",
     "start_time": "2023-04-10T16:41:47.986905Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Missing data cleaned\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: `.applymap()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.applymap()` is used to apply a transformation to each element of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:43:44.984906Z",
     "start_time": "2023-04-10T16:43:42.696406Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This line will apply the base `type()` function to \n",
    "# all entries of the DataFrame.\n",
    "\n",
    "df.applymap(type).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Faster NumPy Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In general, `np.where()` and `np.select()` are faster than `map()`. This won't matter too much with reasonably-sized data but can be a consideration for ***big data***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:46:12.870408Z",
     "start_time": "2023-04-10T16:46:12.849906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's copy the dataframe to play around with\n",
    "level_up = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:46:13.226905Z",
     "start_time": "2023-04-10T16:46:13.194406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "level_up.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## NumPy's `where()` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:46:14.513408Z",
     "start_time": "2023-04-10T16:46:14.468407Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First pass a condition\n",
    "level_up['Adopted1'] = np.where(level_up['Outcome Type'] == 'Adoption',\n",
    "                                True,  # What to fill with if the condition is true\n",
    "                                False)  # What to fill with if not true\n",
    "level_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:46:28.277406Z",
     "start_time": "2023-04-10T16:46:28.207409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "level_up['Adopted2'] = level_up['Outcome Type'].map(lambda x: True if x == 'Adoption' else False)\n",
    "level_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:47:51.899907Z",
     "start_time": "2023-04-10T16:47:44.819406Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's time how long it takes np.where() to run by running it multiple times\n",
    "%timeit np.where(level_up['Outcome Type'] == 'Adoption', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:48:02.703406Z",
     "start_time": "2023-04-10T16:48:00.739906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's time how long it takes .map() to run by running it multiple times\n",
    "%timeit level_up['Outcome Type'].map(lambda x: True if x == 'Adoption' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## NumPy's `select()` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again, `numpy` will be faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:49:03.044907Z",
     "start_time": "2023-04-10T16:49:02.999907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define our list of conditions\n",
    "conditions = [level_up['Sex upon Outcome'] == 'Neutered Male',\n",
    "              level_up['Sex upon Outcome'] == 'Spayed Female',\n",
    "              level_up['Sex upon Outcome'] == 'Intact Male',\n",
    "              level_up['Sex upon Outcome'] == 'Intact Female',\n",
    "              level_up['Sex upon Outcome'] == 'Unknown',\n",
    "              level_up['Sex upon Outcome'].isna()]\n",
    "\n",
    "# Define a matching list of outcomes\n",
    "choices = ['Fixed', 'Fixed', 'Intact', 'Intact', 'Unknown', 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:49:27.875906Z",
     "start_time": "2023-04-10T16:49:27.833406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use np.select\n",
    "level_up['Grouped Sex upon Outcome1'] = np.select(conditions, choices)\n",
    "level_up['Grouped Sex upon Outcome1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:49:47.731407Z",
     "start_time": "2023-04-10T16:49:47.710406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check we got the same results with np.where()\n",
    "(level_up['Grouped Sex upon Outcome1'] != level_up['Grouped Sex upon Outcome']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:50:11.740905Z",
     "start_time": "2023-04-10T16:50:09.568908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's time how long it takes .map() to run by running it multiple times\n",
    "%timeit level_up['Sex upon Outcome'].map(fixed_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:50:20.591405Z",
     "start_time": "2023-04-10T16:50:15.615907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's time how long it takes np.select() to run by running it multiple times\n",
    "%timeit np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
